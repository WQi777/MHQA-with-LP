{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Entity_GCN_GCP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yg-li/MHQA-with-LP/blob/master/Entity_GCN_GCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N4e6IAlpUi05"
      },
      "source": [
        "This notebook is about using Entity-GCN, an algorithm using R-GCN on entity-relations graph to solve the multi-hop QA problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QEBAZov5IUI8",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# read in QAngaroo WikiHop\n",
        "wh_data_path='./wikihop'\n",
        "with open(os.path.join(wh_data_path, 'train.json')) as f:\n",
        "  train_src = json.loads(f.read())\n",
        "with open(os.path.join(wh_data_path, 'dev.json')) as f:\n",
        "  dev_src = json.loads(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YeaMTgZ-E2FE",
        "colab": {}
      },
      "source": [
        "# Paths needed by torch-geometric\n",
        "!export PATH=/usr/local/cuda/bin:$PATH\n",
        "!export CPATH=/usr/local/cuda/include:$CPATH\n",
        "!export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5-ZYvYk8-O6A",
        "colab": {}
      },
      "source": [
        "# # apex for mixed precision training\n",
        "# ! (if ! [ \"$(pip freeze | grep apex)\" ]; then \\\n",
        "#      git clone https://github.com/NVIDIA/apex; \\\n",
        "#      pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex; \\\n",
        "#    fi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQuAXdFMMZ15",
        "colab": {}
      },
      "source": [
        "# # neuralcoref works only with spacy<=2.1.3\n",
        "# ! (if [ \"$(pip freeze | grep spacy | cut -d'=' -f 3)\" != \"2.1.3\" ]; then \\\n",
        "#      pip uninstall -y spacy; \\\n",
        "#      pip install spacy==2.1.3; \\\n",
        "#    fi)\n",
        "# !pip install neuralcoref\n",
        "# !pip install allennlp\n",
        "\n",
        "# !pip install --no-cache-dir torch-scatter torch-sparse torch-cluster\n",
        "# !pip install torch-geometric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EZCwquLR9VM1",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import neuralcoref\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv\n",
        "\n",
        "from apex import amp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lvcKylrJU8z7",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "elmo = ElmoEmbedder(cuda_device=0 if torch.cuda.is_available() else -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S9qi6k0T9MFM"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_xQVn9xr9LMm",
        "colab": {}
      },
      "source": [
        "class QueryEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(QueryEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.lstm1 = nn.LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
        "    self.lstm2 = nn.LSTM(512, 128, batch_first=True, bidirectional=True)\n",
        "    self.h_0 = nn.Parameter(torch.rand((2, 1, 256)))\n",
        "    self.c_0 = nn.Parameter(torch.rand((2, 1, 256)))\n",
        "    self.hidden_map = nn.Linear(256, 128)\n",
        "    self.cell_map = nn.Linear(256, 128)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # batch_size is always 1 as encoding happens per query\n",
        "    x, (h_n, c_n) = self.lstm1(x, (self.h_0, self.c_0))\n",
        "    x = self.dropout(x)\n",
        "    h_n = F.relu(self.hidden_map(h_n))\n",
        "    c_n = F.relu(self.cell_map(c_n))\n",
        "    x, (q, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    q = self.dropout(q.reshape(1, -1))\n",
        "    return q\n",
        "  \n",
        "  \n",
        "class CandidateEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(CandidateEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(3072, 256)\n",
        "    # the following FF layers applied to concat of query and candidates\n",
        "    self.linear2 = nn.Linear(512, 1024)\n",
        "    self.linear3 = nn.Linear(1024, 512)\n",
        "    \n",
        "  def forward(self, x, q):\n",
        "    x = self.dropout(F.relu(self.linear1(x)))\n",
        "    x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(F.relu(self.linear2(x)))\n",
        "    x = self.dropout(F.relu(self.linear3(x)))\n",
        "    return x\n",
        "  \n",
        "  \n",
        "class PyG_RGCN(nn.Module):\n",
        "  def __init__(self, dropout=0, L=3):\n",
        "    super(PyG_RGCN, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.L = L\n",
        "    # all R-GCN layers are sharing weights\n",
        "    self.conv = RGCNConv(512, 512, num_relations=4, num_bases=4)\n",
        "    self.gating = nn.Linear(1024, 1)\n",
        "    \n",
        "  def forward(self, x, edge_index, edge_type):\n",
        "    # L is the number of R-GCN layers\n",
        "    for _ in range(self.L):\n",
        "      u = self.conv(x, edge_index, edge_type)\n",
        "      a = torch.sigmoid(self.gating(torch.cat((u, x), dim=-1)))\n",
        "      x = self.dropout(torch.tanh(u) * a + x * (1-a))\n",
        "    return x \n",
        "\n",
        "class OutputLayer(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(OutputLayer, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(768, 256)\n",
        "    self.linear2 = nn.Linear(256, 128)\n",
        "    self.linear3 = nn.Linear(128, 1)\n",
        "    \n",
        "  def forward(self, x, q):\n",
        "    # batch_size is 1 as instances have different number of candidates\n",
        "    x = torch.cat((q.expand(x.shape[0], -1), x), dim=-1)\n",
        "    x = self.dropout(F.relu(self.linear1(x)))\n",
        "    x = self.dropout(F.relu(self.linear2(x)))\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "labw0S-477BQ"
      },
      "source": [
        "# Build Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sd3LnbHdAx4x"
      },
      "source": [
        "## Extract nodes and edges & Encode mentions with ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UewhVYZsqXsd",
        "colab": {}
      },
      "source": [
        "def extract_info(query, docs, whole_doc, cands, answer,\n",
        "                 query_encoder, cand_encoder):\n",
        "  ''' extract the information needed to build Entity-GCN's graph\n",
        "  Args:\n",
        "    query: the query\n",
        "    docs: spacy annotated documents\n",
        "    whole_doc: spacy annotated concatenated documents\n",
        "    cands: candidates\n",
        "    answer: the correct answer\n",
        "    query_encoder: the encoder for query\n",
        "    cand_encoder: the encoder for candidates given query embedding\n",
        "  Returns:\n",
        "    nodes: nodes of the graph \\\\ dict{id : candidate id (-1 if query entity)}\n",
        "    node_types: 1 for answer, 0 for other candidates, -1 for query entity\n",
        "    node_embeddings: the contextualized embedding of mentions of candidates\n",
        "    query_embedding: the emebdding of query\n",
        "    doc_based_edges: edges that connect mentions in the same document \n",
        "    match_edges: edges that connect exact match \\\\ set((node1, node2))\n",
        "    coref_edges: edges that connect mentions in the same coreference chain \n",
        "    compl_edges: edges that connect all nodes that have not been connected by \n",
        "                 any other types of edges \\\\ set((node1, node2))\n",
        "  ''' \n",
        "  # extract the query entity\n",
        "  query_entity = ' '.join(query.split(' ')[1:])\n",
        "  cands[query_entity] = -1\n",
        "  \n",
        "  # matcher for candidates and query entity\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  patterns = [nlp.make_doc(cand) for cand in cands]\n",
        "  matcher.add(\"CandList\", None, *patterns)\n",
        "\n",
        "  # get embedding of query, q\n",
        "  query_embedding = query_encoder(\n",
        "      torch.as_tensor(\n",
        "          elmo.embed_sentence(\n",
        "              query.split(' ')[0].split('_') + query.split(' ')[1:]\n",
        "          ).reshape(1, -1, 3072), \n",
        "      device=device))\n",
        "  # get elmo for all documents\n",
        "  docs_elmo = [torch.as_tensor(d.reshape(1, -1, 3072), device=device) \n",
        "        for d in elmo.embed_sentences([[w.text for w in doc] for doc in docs])]\n",
        "  \n",
        "  nodes = {}\n",
        "  node_types = []\n",
        "  node_embeddings = []\n",
        "  with_edges = set()\n",
        "  \n",
        "  # sets to store edges\n",
        "  doc_based_edges = set()\n",
        "  match_edges = set()\n",
        "  coref_edges = set()\n",
        "  compl_edges = set()\n",
        "  \n",
        "  # auxiliary variables for cross-document coreference\n",
        "  out_coref_clusters = [[m.text for m in c.mentions] \n",
        "                        for c in whole_doc._.coref_clusters]\n",
        "  out_coref_tmps = [set()] * len(out_coref_clusters) # nodes in same coref chain\n",
        "  \n",
        "  # accumulate nodes, add the doc_based & coreference edges\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    matches = matcher(doc)\n",
        "    in_coref_clusters = [[m.text for m in c.mentions] \n",
        "                         for c in doc._.coref_clusters]\n",
        "    in_coref_tmps = [set()] * len(in_coref_clusters) # nodes in same coref chain\n",
        "    doc_tmp = set() # nodes in the same doc\n",
        "    for _, start, end in matches:\n",
        "      match = doc[start:end].text\n",
        "      new_node = len(nodes)\n",
        "      doc_tmp.add(new_node)\n",
        "      nodes[new_node] = cands.get(match, -1)\n",
        "      node_types.append([1 if match == answer \n",
        "                         else -1 if match == query_entity \n",
        "                         else 0])\n",
        "      match_elmo = docs_elmo[doc_id][:, start:end, :].mean(dim=1) # mean pooling\n",
        "      node_embeddings.append(cand_encoder(match_elmo, query_embedding))\n",
        "      for i, cluster in enumerate(in_coref_clusters):\n",
        "        if match in cluster:\n",
        "          in_coref_tmps[i].add(new_node)\n",
        "      for i, cluster in enumerate(out_coref_clusters):\n",
        "        if match in cluster:\n",
        "          out_coref_tmps[i].add(new_node)\n",
        "          \n",
        "    for pair in itertools.combinations(doc_tmp, 2):\n",
        "      doc_based_edges.add(pair) # doc_based edges\n",
        "      with_edges.update(pair)\n",
        "    for coref_tmp in in_coref_tmps:\n",
        "      for pair in itertools.combinations(coref_tmp, 2):\n",
        "        coref_edges.add(pair) # within-document coref_edges\n",
        "        with_edges.update(pair)\n",
        "        \n",
        "  # cross-document coref_edges\n",
        "  for coref_tmp in out_coref_tmps:\n",
        "    for pair in itertools.combinations(coref_tmp, 2):\n",
        "      coref_edges.add(pair) # cross-document coref_edges\n",
        "      with_edges.update(pair)\n",
        "      \n",
        "  # add exact match edges\n",
        "  for i, j in itertools.combinations(nodes, 2):\n",
        "    if nodes[i] == nodes[j]:\n",
        "      match_edges.add((i,j))\n",
        "      with_edges.update((i,j))\n",
        "      \n",
        "  # add complement edges\n",
        "  isolated_nodes = set(nodes) - with_edges\n",
        "  if isolated_nodes:\n",
        "    for pair in itertools.combinations(isolated_nodes, 2):\n",
        "      compl_edges.add(pair)\n",
        "      \n",
        "  return nodes, node_types, node_embeddings, query_embedding, \\\n",
        "         [doc_based_edges, match_edges, coref_edges, compl_edges]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VE_E01PXA6ne"
      },
      "source": [
        "## PyG graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "na1M8d7XqM2C",
        "colab": {}
      },
      "source": [
        "def build_pyg_graph(nodes, node_types, node_embeddings, query_embedding, edges):\n",
        "  # nodes\n",
        "  x = torch.cat(node_embeddings).squeeze()\n",
        "  # node_name = torch.tensor(list(nodes.values()), device=device)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  # node_mask = (tmp >= 0).to(device) # whether the node is in candidate list\n",
        "  y = (tmp > 0).to(device, torch.float) # target \n",
        "\n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "\n",
        "  data = Data(x=x, query=query_embedding, y=y,\n",
        "              edge_index=edge_index.t().contiguous(), edge_type=edge_type)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GoOp15T9Sxb0",
        "colab": {}
      },
      "source": [
        "def build_graph(instance, query_encoder, cand_encoder, extract=False):\n",
        "  query = instance.get('query').strip()\n",
        "  supports = [text.lower() for text in instance.get('supports')]\n",
        "  docs = [nlp(text) for text in supports]\n",
        "  whole_doc = nlp(' '.join(supports))\n",
        "  cands = dict([(v, i) for i, v in \n",
        "                enumerate([cand.lower().strip() \n",
        "                           for cand in instance.get('candidates')])])\n",
        "  answer = instance.get('answer')\n",
        "  \n",
        "  # extract nodes, edges, and embeddings\n",
        "  nodes, node_types, node_embeddings, query_embedding, edges = \\\n",
        "    extract_info(query, docs, whole_doc, cands, answer, query_encoder, cand_encoder)\n",
        "  if extract:\n",
        "    return nodes, node_types, node_embeddings, query_embedding, edges\n",
        "  \n",
        "  # build PyG graph\n",
        "  g = build_pyg_graph(nodes, node_types, node_embeddings, query_embedding, edges)\n",
        "  \n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TdURez7sCuPz"
      },
      "source": [
        "# Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iSnfyPOZgIlM",
        "colab": {}
      },
      "source": [
        "def save_models(epoch, step, loss_history, optimizer,\n",
        "                query_encoder, cand_encoder, rgcn, output_layer, PATH):\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'step': step,\n",
        "        'loss_history': loss_history,\n",
        "        'query_encoder': query_encoder.state_dict(),\n",
        "        'cand_encoder': cand_encoder.state_dict(),\n",
        "        'rgcn': rgcn.state_dict(),\n",
        "        'output_layer': output_layer.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "  }, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x489ulHRV71k",
        "colab": {}
      },
      "source": [
        "def train(epochs, step, batch_size, optimizer, loss_fn, src, query_encoder, \n",
        "          cand_encoder, rgcn, output_layer, PATH, loss_history=[], tol=1e-3):\n",
        "  query_encoder.train()\n",
        "  cand_encoder.train()\n",
        "  rgcn.train()\n",
        "  output_layer.train()\n",
        "  for e in epochs:\n",
        "    random.shuffle(src)\n",
        "    for i in range(step, len(src)):\n",
        "      try:\n",
        "        optimizer.zero_grad()\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "        # TODO: link predition\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query)\n",
        "        loss = loss_fn(pred, g.y) \n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "          scaled_loss.backward()\n",
        "        optimizer.step()\n",
        "        print('Epoch: {:2d}  [{:d}/{:d}]\\tloss: {:.4f}\\t{}'.format(\n",
        "            e, i+1, len(src), loss.item(), datetime.now()), flush=True)\n",
        "        loss_history.append(loss.item())\n",
        "        del loss\n",
        "      except:\n",
        "        print('Fail graph with id: {}'.format(src[i].get('id')), flush=True)\n",
        "        continue\n",
        "      if i != 0 and i % batch_size == 0 or i == len(src)-1:\n",
        "        # end of a batch\n",
        "        save_models(e, i+1, loss_history, optimizer, \n",
        "            query_encoder, cand_encoder, rgcn, output_layer, \n",
        "            PATH)\n",
        "        print('Model saved', flush=True)\n",
        "        \n",
        "    # end of epoch\n",
        "    save_models(e+1, 0, loss_history, optimizer, \n",
        "        query_encoder, cand_encoder, rgcn, output_layer, \n",
        "        PATH)\n",
        "    if loss_history[-10] - loss_history[-1] < tol:\n",
        "      return query_encoder, cand_encoder, rgcn, output_layer\n",
        "    step = 0\n",
        "  return query_encoder, cand_encoder, rgcn, output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "frpCGWaFWuLv",
        "colab": {}
      },
      "source": [
        "def test(loss_fn, src, query_encoder, cand_encoder, rgcn, output_layer):\n",
        "  query_encoder.eval()\n",
        "  cand_encoder.eval()\n",
        "  rgcn.eval()\n",
        "  output_layer.eval()\n",
        "  \n",
        "  num_processed_graphs = 0\n",
        "  loss_history = []\n",
        "  acc = 0.\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(src)):\n",
        "      try:\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "        # PyG\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query, g.node_mask)\n",
        "        \n",
        "        loss_history.append(loss_fn(pred, g.y).item())\n",
        "        acc += (g.y[pred.argmax(), 0] == 1).item()\n",
        "        num_processed_graphs += 1\n",
        "      except:\n",
        "        print('Fail graph with id: {}'.format(src[i].get('id')), flush=True)\n",
        "        continue\n",
        "      if i % 32 == 0:\n",
        "        print('[{:d}/{:d}]\\tloss: {:.4f}\\tacc: {:.1f}\\t{}'.format(\n",
        "            num_processed_graphs, len(src), loss_history[-1], acc, datetime.now()), flush=True)\n",
        "        \n",
        "  return acc/num_processed_graphs, loss_history     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2pp7lxklJwdt",
        "colab": {}
      },
      "source": [
        "## Training\n",
        "# parameters\n",
        "epochs = range(4)\n",
        "step = 0\n",
        "batch_size = 32\n",
        "L = 3 # number of R-GCN layers\n",
        "lr = 1e-5\n",
        "dropout = 0\n",
        "save_path='./entity_gcn.tar'\n",
        "\n",
        "# models\n",
        "query_encoder = QueryEncoder(dropout=dropout).to(device)\n",
        "cand_encoder = CandidateEncoder(dropout=dropout).to(device)\n",
        "rgcn = PyG_RGCN(dropout=dropout, L=L).to(device)\n",
        "output_layer = OutputLayer(dropout=dropout).to(device)\n",
        "\n",
        "optimizer = Adam(\n",
        "    itertools.chain(\n",
        "        query_encoder.parameters(), \n",
        "        cand_encoder.parameters(), \n",
        "        rgcn.parameters(), \n",
        "        output_layer.parameters()), \n",
        "    lr=lr,\n",
        "    eps=1e-4)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_history = []\n",
        "\n",
        "# load checkpoint\n",
        "if os.path.isfile(save_path):\n",
        "  checkpoint = torch.load(save_path)\n",
        "  epochs = range(checkpoint['epoch'], 20)\n",
        "  step = checkpoint['step']\n",
        "  loss_history = checkpoint['loss_history']\n",
        "  query_encoder.load_state_dict(checkpoint['query_encoder'])\n",
        "  cand_encoder.load_state_dict(checkpoint['cand_encoder'])\n",
        "  rgcn.load_state_dict(checkpoint['rgcn'])\n",
        "  output_layer.load_state_dict(checkpoint['output_layer'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "[query_encoder, cand_encoder, rgcn, output_layer], optimizer = \\\n",
        "  amp.initialize([query_encoder, cand_encoder, rgcn, output_layer], optimizer, opt_level='O1')\n",
        "\n",
        "query_encoder, cand_encoder, rgcn, output_layer = train(\n",
        "    epochs, step, batch_size, optimizer, loss_fn, train_src, query_encoder, \n",
        "    cand_encoder, rgcn, output_layer, save_path, loss_history=loss_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I2ooSEKN63DD",
        "colab": {}
      },
      "source": [
        "## Testing\n",
        "\n",
        "L = 3 # number of R-GCN layers\n",
        "dropout = 0\n",
        "save_path='./entity_gcn.tar'\n",
        "\n",
        "query_encoder = QueryEncoder(dropout=dropout).to(device)\n",
        "cand_encoder = CandidateEncoder(dropout=dropout).to(device)\n",
        "# rgcn = DGL_RGCN(dropout=dropout, num_layers=L).to(device)\n",
        "rgcn = PyG_RGCN(dropout=dropout, L=L).to(device)\n",
        "output_layer = OutputLayer(dropout=dropout).to(device)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "checkpoint = torch.load(save_path)\n",
        "query_encoder.load_state_dict(checkpoint['query_encoder'])\n",
        "cand_encoder.load_state_dict(checkpoint['cand_encoder'])\n",
        "rgcn.load_state_dict(checkpoint['rgcn'])\n",
        "output_layer.load_state_dict(checkpoint['output_layer'])\n",
        "\n",
        "[query_encoder, cand_encoder, rgcn, output_layer] = \\\n",
        "  amp.initialize([query_encoder, cand_encoder, rgcn, output_layer], opt_level='O1')\n",
        "\n",
        "acc, loss_history = test(loss_fn, dev_src, \n",
        "                         query_encoder, cand_encoder, rgcn, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x7Q2hvQCKUPN",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}