{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entity-GCN on WikiHop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yg-li/QA-KG-RL/blob/master/Entity_GCN_on_WikiHop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4e6IAlpUi05",
        "colab_type": "text"
      },
      "source": [
        "This notebook is about using Entity-GCN, an algorithm using R-GCN on entity-relations graph to solve the multi-hop QA problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQuAXdFMMZ15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83f691db-36be-4268-e615-af288cc9754c"
      },
      "source": [
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster\n",
        "!pip install torch-geometric\n",
        "# !pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
        "  \n",
        "! (if [ \"$(pip freeze | grep spacy | cut -d'=' -f 3)\" != \"2.1.3\" ]; then \\\n",
        "     pip uninstall -y spacy; \\\n",
        "     pip install spacy==2.1.3; \\\n",
        "   fi)\n",
        "!pip install neuralcoref\n",
        "!pip install allennlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.6/dist-packages (1.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.16.4)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.2.2)\n",
            "Requirement already satisfied: plyfile in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.24.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.2)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.13.2)\n",
            "Requirement already satisfied: neuralcoref in /usr/local/lib/python3.6/dist-packages (4.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.1.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.9.189)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (1.16.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from neuralcoref) (2.21.0)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.189 in /usr/local/lib/python3.6/dist-packages (from boto3->neuralcoref) (1.12.199)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->neuralcoref) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->neuralcoref) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.189->boto3->neuralcoref) (1.12.0)\n",
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (0.8.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.3)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.8)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.6.2)\n",
            "Requirement already satisfied: awscli>=1.11.91 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.209)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.189)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.1)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.13.0)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: conllu==0.11 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.5.1)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1)\n",
            "Requirement already satisfied: spacy<2.2,>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.3)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.4)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.6)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.9.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.8)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.5.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.15.5)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2019.6.8)\n",
            "Requirement already satisfied: PyYAML<=5.1,>=3.10; python_version != \"2.6\" in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
            "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.4.2)\n",
            "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.3.9)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.2.1)\n",
            "Requirement already satisfied: botocore==1.12.199 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (1.12.199)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (41.0.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.13.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.2.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.2.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.0.7)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.6.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask>=1.0.2->allennlp) (1.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZCwquLR9VM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b9f32e79-0cfa-4f13-d7e7-efb738a4d9a8"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import itertools\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import neuralcoref\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch import autograd\n",
        "\n",
        "# import dgl\n",
        "# import dgl.function as fn\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcKylrJU8z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float16\n",
        "\n",
        "elmo = ElmoEmbedder(cuda_device=0 if torch.cuda.is_available() else -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsXK61rj08Lp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51237ce5-a678-475a-9bdb-fb3acd211aa0"
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# read in QAngaroo WikiHop\n",
        "wh_data_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/data/qangaroo_v1.1/wikihop'\n",
        "with open(os.path.join(wh_data_path, 'train.json')) as f:\n",
        "  train_src = json.loads(f.read())\n",
        "with open(os.path.join(wh_data_path, 'dev.json')) as f:\n",
        "  dev_src = json.loads(f.read())\n",
        "\n",
        "# # read in HotpotQA\n",
        "# hpqa_data_path = '/gdrive/My Drive/Colab Notebooks/CSML/Project/data/hotpotqa'\n",
        "# with open(os.path.join(hpqa_data_path, 'hotpot_train_v1.1.json')) as f:\n",
        "#   train_src = json.loads(f.read())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9qi6k0T9MFM",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xQVn9xr9LMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QueryEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(QueryEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.lstm1 = nn.LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
        "    self.lstm2 = nn.LSTM(512, 128, batch_first=True, bidirectional=True)\n",
        "    self.hidden_map = nn.Linear(256, 128)\n",
        "    self.cell_map = nn.Linear(256, 128)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # batch_size is always 1 as encoding happens per query\n",
        "    x, (h_n, c_n) = self.lstm1(x)\n",
        "    x = self.dropout(F.layer_norm(x, x.shape[1:]))\n",
        "    h_n = self.dropout(F.instance_norm(F.relu(self.hidden_map(h_n))))\n",
        "    c_n = self.dropout(F.instance_norm(F.relu(self.cell_map(c_n))))\n",
        "    x, (q, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    q = self.dropout(F.layer_norm(q, q.shape[1:]).reshape(1, -1, 256))\n",
        "#     print('query', q, flush=True)\n",
        "    return q\n",
        "  \n",
        "  \n",
        "class CandidateEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(CandidateEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(3072, 256)\n",
        "    # the following FF layers applied to concat of query and cand.\n",
        "    self.linear2 = nn.Linear(512, 512)\n",
        "    self.linear3 = nn.Linear(512, 256)\n",
        "    self.bn = nn.BatchNorm1d(1)\n",
        "    \n",
        "  def forward(self, x, q):\n",
        "    x = self.dropout(self.bn(F.relu(self.linear1(x))))\n",
        "    x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(self.bn(F.relu(self.linear2(x))))\n",
        "    x = self.dropout(self.bn(F.relu(self.linear3(x))))\n",
        "#     print('cand', x, flush=True)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "class PyG_RGCN(nn.Module):\n",
        "  def __init__(self, dropout=0, L=3):\n",
        "    super(PyG_RGCN, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.L = L\n",
        "    # all R-GCN layers are sharing weights\n",
        "    self.conv = RGCNConv(256, 256, num_relations=4, num_bases=4)\n",
        "    self.gating = nn.Linear(512, 1)\n",
        "    \n",
        "  def forward(self, x, edge_index, edge_type):\n",
        "    # L is the number of R-GCN layers\n",
        "    for _ in range(self.L):\n",
        "      u = F.instance_norm(self.conv(x, edge_index, edge_type))\n",
        "      a = torch.sigmoid(self.gating(torch.cat((u, x), dim=-1)))\n",
        "      x = self.dropout(torch.tanh(u) * a + x * (1-a))\n",
        "#     print('x', x, flush=True)\n",
        "    return x \n",
        "\n",
        "  \n",
        "# class RGCNLayer(nn.Module): # RGCN layer implemented with DGL\n",
        "#   def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=True,\n",
        "#                activation=None):#, is_input_layer=False):\n",
        "#     super(RGCNLayer, self).__init__()\n",
        "#     self.in_feat = in_feat\n",
        "#     self.out_feat = out_feat\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.bias = bias\n",
        "#     self.activation = activation\n",
        "\n",
        "#     # sanity check\n",
        "#     if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
        "#       self.num_bases = self.num_rels\n",
        "\n",
        "#     # weight bases in equation (3)\n",
        "#     self.weight = nn.Parameter(torch.Tensor(self.num_rels, self.in_feat,\n",
        "#                                             self.out_feat))\n",
        "\n",
        "#     # add bias\n",
        "#     if self.bias:\n",
        "#       self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
        "\n",
        "#     # init trainable parameters\n",
        "#     nn.init.xavier_uniform_(self.weight,\n",
        "#                             gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     weight = self.weight\n",
        "\n",
        "#     def message_func(edges):\n",
        "#       w = weight[edges.data['rel_type']]\n",
        "#       msg = torch.bmm(edges.src['x'].unsqueeze(1), w).squeeze()\n",
        "#       return {'msg': msg}\n",
        "\n",
        "#     def apply_func(nodes):\n",
        "#       h = nodes.data['h']\n",
        "#       if self.bias is not None:\n",
        "#         h = h + self.bias\n",
        "#       if self.activation:\n",
        "#         h = self.activation(h)\n",
        "#       return {'h': h}\n",
        "\n",
        "#     g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)\n",
        "    \n",
        "\n",
        "# class DGL_RGCN(nn.Module):\n",
        "#   def __init__(self, num_rels=4, num_bases=-1, num_layers=3, dropout=0):\n",
        "#     super(DGL_RGCN, self).__init__()\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.num_layers = num_layers\n",
        "#     self.dropout = nn.Dropout(p=dropout)\n",
        "#     self.conv = RGCNLayer(256, 256, self.num_rels, self.num_bases)\n",
        "#     self.gating = nn.Linear(512, 1)\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     for _ in range(self.num_layers):\n",
        "#       self.conv(g)\n",
        "#       u = g.ndata.pop('h')\n",
        "#       a = torch.sigmoid(self.gating(torch.cat((u, g.ndata['x']), dim=-1)))\n",
        "#       g.ndata['x'] = self.dropout(torch.tanh(u) * a + g.ndata['x'] * (1-a))\n",
        "#     return g.ndata.pop('x')\n",
        "  \n",
        "\n",
        "class OutputLayer(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(OutputLayer, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(512, 256)\n",
        "    self.linear2 = nn.Linear(256, 128)\n",
        "    self.linear3 = nn.Linear(128, 1)\n",
        "    self.bn256 = nn.BatchNorm1d(256)\n",
        "    self.bn128 = nn.BatchNorm1d(128)\n",
        "    \n",
        "  def forward(self, x, q, node_mask):\n",
        "    # batch_size is 1 as instances have different number of candidates\n",
        "    if not x.shape[0] == q.shape[0]:\n",
        "      x = torch.cat((q.expand(x.shape[0], -1), x), dim=-1)\n",
        "    else:\n",
        "      x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(self.bn256(F.relu(self.linear1(x))))\n",
        "    x = self.dropout(self.bn128(F.relu(self.linear2(x))))\n",
        "    x = self.linear3(x)\n",
        "    x *= node_mask\n",
        "#     print('out', x, flush=True)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "labw0S-477BQ",
        "colab_type": "text"
      },
      "source": [
        "# Build Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd3LnbHdAx4x",
        "colab_type": "text"
      },
      "source": [
        "## Extract nodes and edges & Encode mentions with ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewhVYZsqXsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_info(query, docs, whole_doc, cands, answer,\n",
        "                 query_encoder, cand_encoder):\n",
        "  ''' extract the information needed to build Entity-GCN's graph\n",
        "  Args:\n",
        "    query: the query\n",
        "    docs: spacy annotated documents\n",
        "    whole_doc: spacy annotated concatenated documents\n",
        "    cands: candidates\n",
        "    answer: the correct answer\n",
        "    query_encoder: the encoder for query\n",
        "    cand_encoder: the encoder for candidates given query embedding\n",
        "  Returns:\n",
        "    nodes: nodes of the graph \\\\ dict{id : candidate id (-1 if query entity)}\n",
        "    node_types: 1 for answer, 0 for other candidates, -1 for query entity\n",
        "    node_embeddings: the contextualized embedding of mentions of candidates\n",
        "    query_embedding: the emebdding of query\n",
        "    doc_based_edges: edges that connect mentions in the same document \n",
        "    match_edges: edges that connect exact match \\\\ set((node1, node2))\n",
        "    coref_edges: edges that connect mentions in the same coreference chain \n",
        "    compl_edges: edges that connect all nodes that have not been connected by \n",
        "                 any other types of edges \\\\ set((node1, node2))\n",
        "  ''' \n",
        "  # extract the query entity\n",
        "  query_entity = ' '.join(query.split(' ')[1:])\n",
        "  cands[query_entity] = -1\n",
        "  \n",
        "  # matcher for candidates and query entity\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  patterns = [nlp.make_doc(cand) for cand in cands]\n",
        "  matcher.add(\"CandList\", None, *patterns)\n",
        "\n",
        "  # get embedding of query, q\n",
        "  query_embedding = query_encoder(\n",
        "      torch.as_tensor(\n",
        "          elmo.embed_sentence(\n",
        "              query.split(' ')[0].split('_') + \n",
        "              query.split(' ')[1:]).reshape(1, -1, 3072), \n",
        "          device=device, dtype=dtype))\n",
        "  # get elmo for all documents\n",
        "  docs_elmo = [torch.as_tensor(d.reshape(1, -1, 3072), device=device, dtype=dtype)\n",
        "               for d in elmo.embed_sentences(\n",
        "                   [[w.text for w in doc] for doc in docs])]\n",
        "  \n",
        "  nodes = {}\n",
        "  node_types = []\n",
        "  node_embeddings = []\n",
        "  with_edges = set()\n",
        "  \n",
        "  # sets to store edges\n",
        "  doc_based_edges = set()\n",
        "  match_edges = set()\n",
        "  coref_edges = set()\n",
        "  compl_edges = set()\n",
        "  \n",
        "  # auxiliary variables for cross-document coreference\n",
        "  out_coref_clusters = [[m.text for m in c.mentions] \n",
        "                        for c in whole_doc._.coref_clusters]\n",
        "  out_coref_tmps = [set()] * len(out_coref_clusters) # nodes in same coref chain\n",
        "  \n",
        "  # accumulate nodes, add the doc_based & coreference edges\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    matches = matcher(doc)\n",
        "    # text = ' '.join([toc.text for toc in doc])\n",
        "    in_coref_clusters = [[m.text for m in c.mentions] \n",
        "                         for c in doc._.coref_clusters]\n",
        "    in_coref_tmps = [set()] * len(in_coref_clusters) # nodes in same coref chain\n",
        "    doc_tmp = set() # nodes in the same doc\n",
        "    for _, start, end in matches:\n",
        "      match = doc[start:end].text\n",
        "      new_node = len(nodes)\n",
        "      doc_tmp.add(new_node)\n",
        "      nodes[new_node] = cands.get(match, -1)\n",
        "      node_types.append([1 if match == answer \n",
        "                         else -1 if match == query_entity \n",
        "                         else 0])\n",
        "      match_elmo = docs_elmo[doc_id][:, start:end, :].mean(dim=1, keepdim=True)\n",
        "      node_embeddings.append(cand_encoder(match_elmo, query_embedding))\n",
        "      for i, cluster in enumerate(in_coref_clusters):\n",
        "        if match in cluster:\n",
        "          in_coref_tmps[i].add(new_node)\n",
        "      for i, cluster in enumerate(out_coref_clusters):\n",
        "        if match in cluster:\n",
        "          out_coref_tmps[i].add(new_node)\n",
        "          \n",
        "    for pair in itertools.combinations(doc_tmp, 2):\n",
        "      doc_based_edges.add(pair) # doc_based edges\n",
        "      with_edges.update(pair)\n",
        "    for coref_tmp in in_coref_tmps:\n",
        "      for pair in itertools.combinations(coref_tmp, 2):\n",
        "        coref_edges.add(pair) # within-document coref_edges\n",
        "        with_edges.update(pair)\n",
        "        \n",
        "  # cross-document coref_edges\n",
        "  for coref_tmp in out_coref_tmps:\n",
        "    for pair in itertools.combinations(coref_tmp, 2):\n",
        "      coref_edges.add(pair) # cross-document coref_edges\n",
        "      with_edges.update(pair)\n",
        "      \n",
        "  # add exact match edges\n",
        "  for i, j in itertools.combinations(nodes, 2):\n",
        "    if nodes[i] == nodes[j]:\n",
        "      match_edges.add((i,j))\n",
        "      with_edges.update((i,j))\n",
        "      \n",
        "  # add complement edges\n",
        "  isolated_nodes = set(nodes) - with_edges\n",
        "  if isolated_nodes:\n",
        "    for pair in itertools.combinations(isolated_nodes, 2):\n",
        "      compl_edges.add(pair)\n",
        "      \n",
        "  return nodes, node_types, node_embeddings, query_embedding, \\\n",
        "         [doc_based_edges, match_edges, coref_edges, compl_edges]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE_E01PXA6ne",
        "colab_type": "text"
      },
      "source": [
        "## PyG graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1M8d7XqM2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_pyg_graph(nodes, node_types, node_embeddings, query_embedding, edges):\n",
        "  # nodes\n",
        "  x = torch.cat(node_embeddings).squeeze()\n",
        "  node_name = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  node_mask = (tmp >= 0).to(device, dtype) # whether the node is in candidate list\n",
        "  y = (tmp > 0).to(device, dtype) # target \n",
        "\n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "\n",
        "  data = Data(x=x, node_name=node_name, node_mask=node_mask, \n",
        "              query=query_embedding.reshape(-1, 256), y=y,\n",
        "              edge_index=edge_index.t().contiguous(), edge_type=edge_type)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SijcVUbVDFQ",
        "colab_type": "text"
      },
      "source": [
        "## DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-MkrfBVNou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dgl_graph(nodes, node_types, \n",
        "                    node_embeddings, query_embedding, edges):\n",
        "  g = dgl.DGLGraph()\n",
        "  \n",
        "  # nodes\n",
        "  g.add_nodes(len(nodes))\n",
        "  g.ndata['x'] = torch.cat(node_embeddings).squeeze()\n",
        "  g.ndata['name'] = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  g.ndata['mask'] = (tmp >= 0).to(device, dtype)\n",
        "  g.ndata['y'] = (tmp > 0).to(device, dtype)\n",
        "  g.ndata['q'] = query_embedding.reshape(-1, 256).expand(g.number_of_nodes(), -1)\n",
        "  \n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "  g.add_edges(edge_index[:,0], edge_index[:,1])    \n",
        "  g.edata['rel_type'] = edge_type\n",
        "  \n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoOp15T9Sxb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_graph(instance, query_encoder, cand_encoder, extract=False):\n",
        "  query = instance.get('query').strip()\n",
        "  supports = [text.lower() for text in instance.get('supports')]\n",
        "  docs = [nlp(text) for text in supports]\n",
        "  whole_doc = nlp(' '.join(supports))\n",
        "  cands = dict([(v, i) for i, v in \n",
        "                enumerate([cand.lower().strip() \n",
        "                           for cand in instance.get('candidates')])])\n",
        "  answer = instance.get('answer')\n",
        "  \n",
        "  # extract nodes, edges, and embeddings\n",
        "  nodes, node_types, node_embeddings, query_embedding, edges = \\\n",
        "    extract_info(query, docs, whole_doc, cands, answer, \n",
        "                 query_encoder, cand_encoder)\n",
        "  if extract:\n",
        "    return nodes, node_types, node_embeddings, query_embedding, edges\n",
        "  \n",
        "  # build PyG graph\n",
        "  g = build_pyg_graph(nodes, node_types, \n",
        "                      node_embeddings, query_embedding, edges)\n",
        "\n",
        "  # build DGL graph\n",
        "#   g = build_dgl_graph(nodes, node_types, \n",
        "#                       node_embeddings, query_embedding, edges)\n",
        "  return g # query, cands, answer   TODO: check the output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdURez7sCuPz",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSnfyPOZgIlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch, step, loss_history, optimizer,\n",
        "                query_encoder, cand_encoder, rgcn, output_layer, PATH):\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'step': step,\n",
        "        'loss_history': loss_history,\n",
        "        'query_encoder': query_encoder.state_dict(),\n",
        "        'cand_encoder': cand_encoder.state_dict(),\n",
        "        'rgcn': rgcn.state_dict(),\n",
        "        'output_layer': output_layer.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "  }, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x489ulHRV71k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, step, batch_size, optimizer, loss_fn, src, query_encoder, \n",
        "          cand_encoder, rgcn, output_layer, PATH, loss_history=[], tol=1e-3):\n",
        "  query_encoder.train()\n",
        "  cand_encoder.train()\n",
        "  rgcn.train()\n",
        "  output_layer.train()\n",
        "  for e in epochs:\n",
        "    random.shuffle(src)\n",
        "    for i in range(step, len(src)):\n",
        "#       if i % batch_size == 0:\n",
        "        # start of a batch\n",
        "      optimizer.zero_grad()\n",
        "      try:\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "      \n",
        "        # PyG\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query, g.node_mask)\n",
        "        loss = loss_fn(pred, g.y) # TODO: maybe need to scale for batch\n",
        "\n",
        "#         # DGL\n",
        "#         out = rgcn(g)\n",
        "#         pred = output_layer(out, g.ndata['q'], g.ndata['mask'])\n",
        "#         loss = loss_fn(pred, g.ndata['y'])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      except:\n",
        "        print('Fail graph with id: {}'.format(src[i].get('id')), flush=True)\n",
        "        continue\n",
        "      print('Epoch: {:2d}  [{:d}/{:d}]\\tloss: {:.4f}\\t{}'.format(\n",
        "          e, i+1, len(src), loss.item(), datetime.now()), flush=True)\n",
        "      loss_history.append(loss.item())\n",
        "    \n",
        "      if i != 0 and i % batch_size == 0 or i == len(src)-1:\n",
        "        # end of a batch\n",
        "        save_models(e, i+1, loss_history, optimizer, \n",
        "            query_encoder, cand_encoder, rgcn, output_layer, \n",
        "            PATH)\n",
        "        \n",
        "    # end of epoch\n",
        "    save_models(e+1, 0, loss_history, optimizer, \n",
        "        query_encoder, cand_encoder, rgcn, output_layer, \n",
        "        PATH)\n",
        "    if loss_history[-10] - loss_history[-1] < tol:\n",
        "      return query_encoder, cand_encoder, rgcn, output_layer\n",
        "  return query_encoder, cand_encoder, rgcn, output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pp7lxklJwdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "50a2c139-4288-47ab-c477-ea45cba94158"
      },
      "source": [
        "# parameters\n",
        "epochs = range(20)\n",
        "step = 0\n",
        "batch_size = 32\n",
        "L = 1 # number of R-GCN layers\n",
        "lr = 1e-4\n",
        "dropout = 0\n",
        "save_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/checkpoint/entity_gcn_gpu.tar'\n",
        "\n",
        "# models\n",
        "query_encoder = QueryEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "cand_encoder = CandidateEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "# rgcn = DGL_RGCN(dropout=dropout, num_layers=L).to(device, dtype=dtype)\n",
        "rgcn = PyG_RGCN(dropout=dropout, L=L).to(device, dtype=dtype)\n",
        "output_layer = OutputLayer(dropout=dropout).to(device, dtype=dtype)\n",
        "\n",
        "optimizer = Adam(\n",
        "    itertools.chain(\n",
        "        query_encoder.parameters(), \n",
        "        cand_encoder.parameters(), \n",
        "        rgcn.parameters(), \n",
        "        output_layer.parameters()), \n",
        "    lr=lr,\n",
        "    eps=1e-4)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_history = []\n",
        "\n",
        "# load checkpoint\n",
        "if os.path.isfile(save_path):\n",
        "  checkpoint = torch.load(save_path)\n",
        "  epoch = checkpoint['epoch']\n",
        "  step = checkpoint['step']\n",
        "  loss_history = checkpoint['loss_history']\n",
        "  query_encoder.load_state_dict(checkpoint['query_encoder'])\n",
        "  cand_encoder.load_state_dict(checkpoint['cand_encoder'])\n",
        "  rgcn.load_state_dict(checkpoint['rgcn'])\n",
        "  output_layer.load_state_dict(checkpoint['output_layer'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "query_encoder, cand_encoder, rgcn, output_layer = train(\n",
        "    epochs, step, batch_size, optimizer, loss_fn, train_src, query_encoder, \n",
        "    cand_encoder, rgcn, output_layer, save_path, loss_history=loss_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  [1/43738]\tloss: 0.6636\t2019-07-31 16:47:38.566958\n",
            "Epoch:  0  [2/43738]\tloss: 0.6689\t2019-07-31 16:47:47.464667\n",
            "Epoch:  0  [3/43738]\tloss: 0.6104\t2019-07-31 16:47:50.112653\n",
            "Epoch:  0  [4/43738]\tloss: 0.7432\t2019-07-31 16:47:54.407665\n",
            "Epoch:  0  [5/43738]\tloss: 0.6880\t2019-07-31 16:47:59.961360\n",
            "Epoch:  0  [6/43738]\tloss: 0.6831\t2019-07-31 16:48:05.457013\n",
            "Epoch:  0  [7/43738]\tloss: 0.6660\t2019-07-31 16:48:14.149994\n",
            "Epoch:  0  [8/43738]\tloss: 0.6694\t2019-07-31 16:48:18.413488\n",
            "Epoch:  0  [9/43738]\tloss: 0.7173\t2019-07-31 16:48:20.314908\n",
            "Epoch:  0  [10/43738]\tloss: 0.6670\t2019-07-31 16:48:34.663424\n",
            "Epoch:  0  [11/43738]\tloss: 0.7422\t2019-07-31 16:48:36.819706\n",
            "Epoch:  0  [12/43738]\tloss: 0.6553\t2019-07-31 16:48:38.999963\n",
            "Epoch:  0  [13/43738]\tloss: 0.6802\t2019-07-31 16:48:41.424802\n",
            "Epoch:  0  [14/43738]\tloss: 0.6738\t2019-07-31 16:48:47.664416\n",
            "Epoch:  0  [15/43738]\tloss: 0.7407\t2019-07-31 16:48:49.356256\n",
            "Epoch:  0  [16/43738]\tloss: 0.6455\t2019-07-31 16:48:50.690632\n",
            "Epoch:  0  [17/43738]\tloss: 0.6890\t2019-07-31 16:48:56.974703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaoOWKGnC2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# g = build_graph(train_src[2], query_encoder, cand_encoder)\n",
        "# nodes, node_types, node_embeddings, query_embedding, edges = build_graph(train_src[76], query_encoder, cand_encoder, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2ooSEKN63DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}