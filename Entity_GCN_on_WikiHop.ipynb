{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entity-GCN on WikiHop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yg-li/QA-KG-RL/blob/master/Entity_GCN_on_WikiHop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4e6IAlpUi05",
        "colab_type": "text"
      },
      "source": [
        "This notebook is about using Entity-GCN, an algorithm using R-GCN on entity-relations graph to solve the multi-hop QA problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQuAXdFMMZ15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster\n",
        "!pip install torch-geometric\n",
        "# !pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
        "  \n",
        "! (if [ \"$(pip freeze | grep spacy | cut -d'=' -f 3)\" != \"2.1.3\" ]; then \\\n",
        "     pip uninstall -y spacy; \\\n",
        "     pip install spacy==2.1.3; \\\n",
        "   fi)\n",
        "!pip install neuralcoref\n",
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZCwquLR9VM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import itertools\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import neuralcoref\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "# import dgl\n",
        "# import dgl.function as fn\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcKylrJU8z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float16\n",
        "\n",
        "elmo = ElmoEmbedder(cuda_device=0 if torch.cuda.is_available() else -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsXK61rj08Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# read in QAngaroo WikiHop\n",
        "wh_data_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/data/qangaroo_v1.1/wikihop'\n",
        "with open(os.path.join(wh_data_path, 'train.json')) as f:\n",
        "  train_src = json.loads(f.read())\n",
        "with open(os.path.join(wh_data_path, 'dev.json')) as f:\n",
        "  dev_src = json.loads(f.read())\n",
        "\n",
        "# # read in HotpotQA\n",
        "# hpqa_data_path = '/gdrive/My Drive/Colab Notebooks/CSML/Project/data/hotpotqa'\n",
        "# with open(os.path.join(hpqa_data_path, 'hotpot_train_v1.1.json')) as f:\n",
        "#   train_src = json.loads(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9qi6k0T9MFM",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xQVn9xr9LMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QueryEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(QueryEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.lstm1 = nn.LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
        "    self.lstm2 = nn.LSTM(512, 128, batch_first=True, bidirectional=True)\n",
        "    self.hidden_map = nn.Linear(256, 128)\n",
        "    self.cell_map = nn.Linear(256, 128)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # batch_size is always 1 as encoding happens per query\n",
        "    x, (h_n, c_n) = self.lstm1(x)\n",
        "    x = self.dropout(F.layer_norm(x))\n",
        "    h_n = self.dropout(F.batch_norm(F.relu(self.hidden_map(h_n))))\n",
        "    c_n = self.dropout(F.batch_norm(F.relu(self.cell_map(c_n))))\n",
        "    x, (q, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    q = self.dropout(F.layer_norm(q).reshape(1, -1, 256))\n",
        "    return q\n",
        "  \n",
        "  \n",
        "class CandidateEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(CandidateEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(3072, 256)\n",
        "    # the following FF layers applied to concat of query and cand.\n",
        "    self.linear2 = nn.Linear(512, 512)\n",
        "    self.linear3 = nn.Linear(512, 256)\n",
        "    \n",
        "  def forward(self, x, q):\n",
        "    x = self.dropout(F.batch_norm(F.relu(self.linear1(x))))\n",
        "    x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(F.batch_norm(F.relu(self.linear2(x))))\n",
        "    x = self.dropout(F.batch_norm(F.relu(self.linear3(x))))\n",
        "    return x\n",
        "  \n",
        "  \n",
        "class PyG_RGCN(nn.Module):\n",
        "  def __init__(self, dropout=0, L=3):\n",
        "    super(PyG_RGCN, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.L = L\n",
        "    # all R-GCN layers are sharing weights\n",
        "    self.conv = RGCNConv(256, 256, num_relations=4, num_bases=4)\n",
        "    self.gating = nn.Linear(512, 1)\n",
        "    \n",
        "  def forward(self, x, edge_index, edge_type):\n",
        "    # L is the number of R-GCN layers\n",
        "    for _ in range(self.L):\n",
        "      u = F.instance_norm(self.conv(x, edge_index, edge_type))\n",
        "      a = torch.sigmoid(self.gating(torch.cat((u, x), dim=-1)))\n",
        "      x = self.dropout(torch.tanh(u) * a + x * (1-a))\n",
        "    return x \n",
        "\n",
        "  \n",
        "# class RGCNLayer(nn.Module): # RGCN layer implemented with DGL\n",
        "#   def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=True,\n",
        "#                activation=None):#, is_input_layer=False):\n",
        "#     super(RGCNLayer, self).__init__()\n",
        "#     self.in_feat = in_feat\n",
        "#     self.out_feat = out_feat\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.bias = bias\n",
        "#     self.activation = activation\n",
        "\n",
        "#     # sanity check\n",
        "#     if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
        "#       self.num_bases = self.num_rels\n",
        "\n",
        "#     # weight bases in equation (3)\n",
        "#     self.weight = nn.Parameter(torch.Tensor(self.num_rels, self.in_feat,\n",
        "#                                             self.out_feat))\n",
        "\n",
        "#     # add bias\n",
        "#     if self.bias:\n",
        "#       self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
        "\n",
        "#     # init trainable parameters\n",
        "#     nn.init.xavier_uniform_(self.weight,\n",
        "#                             gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     weight = self.weight\n",
        "\n",
        "#     def message_func(edges):\n",
        "#       w = weight[edges.data['rel_type']]\n",
        "#       msg = torch.bmm(edges.src['x'].unsqueeze(1), w).squeeze()\n",
        "#       return {'msg': msg}\n",
        "\n",
        "#     def apply_func(nodes):\n",
        "#       h = nodes.data['h']\n",
        "#       if self.bias is not None:\n",
        "#         h = h + self.bias\n",
        "#       if self.activation:\n",
        "#         h = self.activation(h)\n",
        "#       return {'h': h}\n",
        "\n",
        "#     g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)\n",
        "    \n",
        "\n",
        "# class DGL_RGCN(nn.Module):\n",
        "#   def __init__(self, num_rels=4, num_bases=-1, num_layers=3, dropout=0):\n",
        "#     super(DGL_RGCN, self).__init__()\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.num_layers = num_layers\n",
        "#     self.dropout = nn.Dropout(p=dropout)\n",
        "#     self.conv = RGCNLayer(256, 256, self.num_rels, self.num_bases)\n",
        "#     self.gating = nn.Linear(512, 1)\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     for _ in range(self.num_layers):\n",
        "#       self.conv(g)\n",
        "#       u = g.ndata.pop('h')\n",
        "#       a = torch.sigmoid(self.gating(torch.cat((u, g.ndata['x']), dim=-1)))\n",
        "#       g.ndata['x'] = self.dropout(torch.tanh(u) * a + g.ndata['x'] * (1-a))\n",
        "#     return g.ndata.pop('x')\n",
        "  \n",
        "\n",
        "class OutputLayer(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(OutputLayer, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(512, 256)\n",
        "    self.linear2 = nn.Linear(256, 128)\n",
        "    self.linear3 = nn.Linear(128, 1)\n",
        "    \n",
        "  def forward(self, x, q, node_mask):\n",
        "    # batch_size is 1 as instances have different number of candidates\n",
        "    if not x.shape[0] == q.shape[0]:\n",
        "      x = torch.cat((q.expand(x.shape[0], -1), x), dim=-1)\n",
        "    else:\n",
        "      x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(F.batch_norm(F.relu(self.linear1(x))))\n",
        "    x = self.dropout(F.batch_norm(F.relu(self.linear2(x))))\n",
        "    x = self.linear3(x)\n",
        "    x *= node_mask\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "labw0S-477BQ",
        "colab_type": "text"
      },
      "source": [
        "# Build Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd3LnbHdAx4x",
        "colab_type": "text"
      },
      "source": [
        "## Extract nodes and edges & Encode mentions with ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewhVYZsqXsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_info(query, docs, whole_doc, cands, answer,\n",
        "                 query_encoder, cand_encoder):\n",
        "  ''' extract the information needed to build Entity-GCN's graph\n",
        "  Args:\n",
        "    query: the query\n",
        "    docs: spacy annotated documents\n",
        "    whole_doc: spacy annotated concatenated documents\n",
        "    cands: candidates\n",
        "    answer: the correct answer\n",
        "    query_encoder: the encoder for query\n",
        "    cand_encoder: the encoder for candidates given query embedding\n",
        "  Returns:\n",
        "    nodes: nodes of the graph \\\\ dict{id : candidate id (-1 if query entity)}\n",
        "    node_types: 1 for answer, 0 for other candidates, -1 for query entity\n",
        "    node_embeddings: the contextualized embedding of mentions of candidates\n",
        "    query_embedding: the emebdding of query\n",
        "    doc_based_edges: edges that connect mentions in the same document \n",
        "    match_edges: edges that connect exact match \\\\ set((node1, node2))\n",
        "    coref_edges: edges that connect mentions in the same coreference chain \n",
        "    compl_edges: edges that connect all nodes that have not been connected by \n",
        "                 any other types of edges \\\\ set((node1, node2))\n",
        "  ''' \n",
        "  # extract the query entity\n",
        "  query_entity = ' '.join(query.split(' ')[1:])\n",
        "  cands[query_entity] = -1\n",
        "  \n",
        "  # matcher for candidates and query entity\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  patterns = [nlp.make_doc(cand) for cand in cands]\n",
        "  matcher.add(\"CandList\", None, *patterns)\n",
        "\n",
        "  # get embedding of query, q\n",
        "  query_embedding = query_encoder(\n",
        "      torch.as_tensor(\n",
        "          elmo.embed_sentence(\n",
        "              query.split(' ')[0].split('_') + \n",
        "              query.split(' ')[1:]).reshape(1, -1, 3072), \n",
        "          device=device, dtype=dtype))\n",
        "  # get elmo for all documents\n",
        "  docs_elmo = [torch.as_tensor(d.reshape(1, -1, 3072), device=device, dtype=dtype)\n",
        "               for d in elmo.embed_sentences(\n",
        "                   [[w.text for w in doc] for doc in docs])]\n",
        "  \n",
        "  nodes = {}\n",
        "  node_types = []\n",
        "  node_embeddings = []\n",
        "  with_edges = set()\n",
        "  \n",
        "  # sets to store edges\n",
        "  doc_based_edges = set()\n",
        "  match_edges = set()\n",
        "  coref_edges = set()\n",
        "  compl_edges = set()\n",
        "  \n",
        "  # auxiliary variables for cross-document coreference\n",
        "  out_coref_clusters = [[m.text for m in c.mentions] \n",
        "                        for c in whole_doc._.coref_clusters]\n",
        "  out_coref_tmps = [set()] * len(out_coref_clusters) # nodes in same coref chain\n",
        "  \n",
        "  # accumulate nodes, add the doc_based & coreference edges\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    matches = matcher(doc)\n",
        "    # text = ' '.join([toc.text for toc in doc])\n",
        "    in_coref_clusters = [[m.text for m in c.mentions] \n",
        "                         for c in doc._.coref_clusters]\n",
        "    in_coref_tmps = [set()] * len(in_coref_clusters) # nodes in same coref chain\n",
        "    doc_tmp = set() # nodes in the same doc\n",
        "    for _, start, end in matches:\n",
        "      match = doc[start:end].text\n",
        "      new_node = len(nodes)\n",
        "      doc_tmp.add(new_node)\n",
        "      nodes[new_node] = cands.get(match, -1)\n",
        "      node_types.append([1 if match == answer \n",
        "                         else -1 if match == query_entity \n",
        "                         else 0])\n",
        "      match_elmo = docs_elmo[doc_id][:, start:end, :].mean(dim=1, keepdim=True)\n",
        "      node_embeddings.append(cand_encoder(match_elmo, query_embedding))\n",
        "      for i, cluster in enumerate(in_coref_clusters):\n",
        "        if match in cluster:\n",
        "          in_coref_tmps[i].add(new_node)\n",
        "      for i, cluster in enumerate(out_coref_clusters):\n",
        "        if match in cluster:\n",
        "          out_coref_tmps[i].add(new_node)\n",
        "          \n",
        "    for pair in itertools.combinations(doc_tmp, 2):\n",
        "      doc_based_edges.add(pair) # doc_based edges\n",
        "      with_edges.update(pair)\n",
        "    for coref_tmp in in_coref_tmps:\n",
        "      for pair in itertools.combinations(coref_tmp, 2):\n",
        "        coref_edges.add(pair) # within-document coref_edges\n",
        "        with_edges.update(pair)\n",
        "        \n",
        "  # cross-document coref_edges\n",
        "  for coref_tmp in out_coref_tmps:\n",
        "    for pair in itertools.combinations(coref_tmp, 2):\n",
        "      coref_edges.add(pair) # cross-document coref_edges\n",
        "      with_edges.update(pair)\n",
        "      \n",
        "  # add exact match edges\n",
        "  for i, j in itertools.combinations(nodes, 2):\n",
        "    if nodes[i] == nodes[j]:\n",
        "      match_edges.add((i,j))\n",
        "      with_edges.update((i,j))\n",
        "      \n",
        "  # add complement edges\n",
        "  isolated_nodes = set(nodes) - with_edges\n",
        "  if isolated_nodes:\n",
        "    for pair in itertools.combinations(isolated_nodes, 2):\n",
        "      compl_edges.add(pair)\n",
        "      \n",
        "  return nodes, node_types, node_embeddings, query_embedding, \\\n",
        "         [doc_based_edges, match_edges, coref_edges, compl_edges]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE_E01PXA6ne",
        "colab_type": "text"
      },
      "source": [
        "## PyG graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1M8d7XqM2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_pyg_graph(nodes, node_types, node_embeddings, query_embedding, edges):\n",
        "  # nodes\n",
        "  x = torch.cat(node_embeddings).squeeze()\n",
        "  node_name = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  node_mask = (tmp >= 0).to(device, dtype) # whether the node is in candidate list\n",
        "  y = (tmp > 0).to(device, dtype) # target \n",
        "\n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "\n",
        "  data = Data(x=x, node_name=node_name, node_mask=node_mask, \n",
        "              query=query_embedding.reshape(-1, 256), y=y,\n",
        "              edge_index=edge_index.t().contiguous(), edge_type=edge_type)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SijcVUbVDFQ",
        "colab_type": "text"
      },
      "source": [
        "## DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-MkrfBVNou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dgl_graph(nodes, node_types, \n",
        "                    node_embeddings, query_embedding, edges):\n",
        "  g = dgl.DGLGraph()\n",
        "  \n",
        "  # nodes\n",
        "  g.add_nodes(len(nodes))\n",
        "  g.ndata['x'] = torch.cat(node_embeddings).squeeze()\n",
        "  g.ndata['name'] = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  g.ndata['mask'] = (tmp >= 0).to(device, dtype)\n",
        "  g.ndata['y'] = (tmp > 0).to(device, dtype)\n",
        "  g.ndata['q'] = query_embedding.reshape(-1, 256).expand(g.number_of_nodes(), -1)\n",
        "  \n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "  g.add_edges(edge_index[:,0], edge_index[:,1])    \n",
        "  g.edata['rel_type'] = edge_type\n",
        "  \n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoOp15T9Sxb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_graph(instance, query_encoder, cand_encoder):\n",
        "  query = instance.get('query').strip()\n",
        "  supports = [text.lower() for text in instance.get('supports')]\n",
        "  docs = [nlp(text) for text in supports]\n",
        "  whole_doc = nlp(' '.join(supports))\n",
        "  cands = dict([(v, i) for i, v in \n",
        "                enumerate([cand.lower().strip() \n",
        "                           for cand in instance.get('candidates')])])\n",
        "  answer = instance.get('answer')\n",
        "  \n",
        "  # extract nodes, edges, and embeddings\n",
        "  nodes, node_types, node_embeddings, query_embedding, edges = \\\n",
        "    extract_info(query, docs, whole_doc, cands, answer, \n",
        "                 query_encoder, cand_encoder)\n",
        "  \n",
        "  # build PyG graph\n",
        "  g = build_pyg_graph(nodes, node_types, \n",
        "                      node_embeddings, query_embedding, edges)\n",
        "\n",
        "  # build DGL graph\n",
        "#   g = build_dgl_graph(nodes, node_types, \n",
        "#                       node_embeddings, query_embedding, edges)\n",
        "  return g # query, cands, answer   TODO: check the output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdURez7sCuPz",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSnfyPOZgIlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch, loss_history, optimizer,\n",
        "                query_encoder, cand_encoder, rgcn, output_layer, PATH):\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'loss_history': loss_history,\n",
        "        'query_encoder': query_encoder.state_dict(),\n",
        "        'cand_encoder': cand_encoder.state_dict(),\n",
        "        'rgcn': rgcn.state_dict(),\n",
        "        'output_layer': output_layer.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "  }, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x489ulHRV71k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, batch_size, optimizer, loss_fn, src, query_encoder, \n",
        "          cand_encoder, rgcn, output_layer, PATH, loss_history=[], tol=1e-3):\n",
        "  query_encoder.train()\n",
        "  cand_encoder.train()\n",
        "  rgcn.train()\n",
        "  output_layer.train()\n",
        "  for e in epochs:\n",
        "    random.shuffle(src)\n",
        "    for i in range(len(src)):\n",
        "      if i % batch_size == 0:\n",
        "        # start of a batch\n",
        "        optimizer.zero_grad()\n",
        "      with autograd.detect_anomaly():\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "        # PyG\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query, g.node_mask)\n",
        "        loss = loss_fn(pred, g.y) # TODO: maybe need to scale for batch\n",
        "        # DGL\n",
        "  #       out = rgcn(g)\n",
        "  #       pred = output_layer(out, g.ndata['q'], g.ndata['mask'])\n",
        "  #       loss = loss_fn(pred, g.ndata['y'])\n",
        "\n",
        "        loss.backward()\n",
        "      print('Epoch: {:2d}  [{:d}/{:d}]\\tloss: {:.4f}\\t{}'.format(\n",
        "          e, i+1, len(src), loss.item(), datetime.now()), flush=True)\n",
        "      if i != 0 and i % batch_size == 0 or i == len(src)-1:\n",
        "        # end of a batch\n",
        "        optimizer.step()\n",
        "        save_models(e, loss_history, optimizer, \n",
        "            query_encoder, cand_encoder, rgcn, output_layer, \n",
        "            PATH)\n",
        "    # end of epoch\n",
        "    save_models(e+1, loss_history, optimizer, \n",
        "        query_encoder, cand_encoder, rgcn, output_layer, \n",
        "        PATH)\n",
        "    if loss_history[-10] - loss_history[-1] < tol:\n",
        "      return query_encoder, cand_encoder, rgcn, output_layer\n",
        "  return query_encoder, cand_encoder, rgcn, output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pp7lxklJwdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c0ab792-56c7-49ec-e75c-c37950a3ebe0"
      },
      "source": [
        "# parameters\n",
        "epochs = range(20)\n",
        "batch_size = 32\n",
        "L = 1 # number of R-GCN layers\n",
        "lr = 1e-4\n",
        "dropout = 0\n",
        "save_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/checkpoint/entity_gcn_gpu.pt'\n",
        "\n",
        "# models\n",
        "query_encoder = QueryEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "cand_encoder = CandidateEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "# rgcn = DGL_RGCN(dropout=dropout, num_layers=L).to(device, dtype=dtype)\n",
        "rgcn = PyG_RGCN(dropout=dropout, L=L).to(device, dtype=dtype)\n",
        "output_layer = OutputLayer(dropout=dropout).to(device, dtype=dtype)\n",
        "\n",
        "optimizer = Adam(\n",
        "    itertools.chain(\n",
        "        query_encoder.parameters(), \n",
        "        cand_encoder.parameters(), \n",
        "        rgcn.parameters(), \n",
        "        output_layer.parameters()), \n",
        "    lr=lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_history = []\n",
        "\n",
        "query_encoder, cand_encoder, rgcn, output_layer = train(\n",
        "    epochs, batch_size, optimizer, loss_fn, train_src, query_encoder, \n",
        "    cand_encoder, rgcn, output_layer, save_path, loss_history=loss_history)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0  [1/43738]\tloss: 0.6748\t2019-07-31 09:56:41.879812\n",
            "Epoch:  0  [2/43738]\tloss: 0.6812\t2019-07-31 09:56:44.101152\n",
            "Epoch:  0  [3/43738]\tloss: 0.6782\t2019-07-31 09:56:47.532726\n",
            "Epoch:  0  [4/43738]\tloss: 0.6753\t2019-07-31 09:56:53.741540\n",
            "Epoch:  0  [5/43738]\tloss: 0.6763\t2019-07-31 09:56:54.541707\n",
            "Epoch:  0  [6/43738]\tloss: 0.6787\t2019-07-31 09:57:06.447151\n",
            "Epoch:  0  [7/43738]\tloss: 0.6782\t2019-07-31 09:57:07.775519\n",
            "Epoch:  0  [8/43738]\tloss: 0.6875\t2019-07-31 09:57:13.719553\n",
            "Epoch:  0  [9/43738]\tloss: 0.6724\t2019-07-31 09:57:16.835262\n",
            "Epoch:  0  [10/43738]\tloss: 0.6768\t2019-07-31 09:57:18.293348\n",
            "Epoch:  0  [11/43738]\tloss: 0.6821\t2019-07-31 09:57:19.590784\n",
            "Epoch:  0  [12/43738]\tloss: 0.6738\t2019-07-31 09:57:22.347044\n",
            "Epoch:  0  [13/43738]\tloss: 0.6826\t2019-07-31 09:57:34.073896\n",
            "Epoch:  0  [14/43738]\tloss: 0.6875\t2019-07-31 09:57:37.220680\n",
            "Epoch:  0  [15/43738]\tloss: 0.6719\t2019-07-31 09:57:41.448480\n",
            "Epoch:  0  [16/43738]\tloss: 0.6807\t2019-07-31 09:57:45.505489\n",
            "Epoch:  0  [17/43738]\tloss: 0.6709\t2019-07-31 09:57:50.562965\n",
            "Epoch:  0  [18/43738]\tloss: 0.6763\t2019-07-31 09:57:55.241811\n",
            "Epoch:  0  [19/43738]\tloss: 0.6694\t2019-07-31 09:57:57.653024\n",
            "Epoch:  0  [20/43738]\tloss: 0.6743\t2019-07-31 09:58:01.098223\n",
            "Epoch:  0  [21/43738]\tloss: 0.6909\t2019-07-31 09:58:03.024646\n",
            "Epoch:  0  [22/43738]\tloss: 0.6738\t2019-07-31 09:58:06.729040\n",
            "Epoch:  0  [23/43738]\tloss: 0.6826\t2019-07-31 09:58:09.543053\n",
            "Epoch:  0  [24/43738]\tloss: 0.6782\t2019-07-31 09:58:15.453032\n",
            "Epoch:  0  [25/43738]\tloss: 0.6768\t2019-07-31 09:58:26.742270\n",
            "Epoch:  0  [26/43738]\tloss: 0.6807\t2019-07-31 09:58:31.510347\n",
            "Epoch:  0  [27/43738]\tloss: 0.6782\t2019-07-31 09:58:35.875553\n",
            "Epoch:  0  [28/43738]\tloss: 0.6714\t2019-07-31 09:58:40.353635\n",
            "Epoch:  0  [29/43738]\tloss: 0.6729\t2019-07-31 09:58:46.921509\n",
            "Epoch:  0  [30/43738]\tloss: 0.6733\t2019-07-31 09:58:58.596188\n",
            "Epoch:  0  [31/43738]\tloss: 0.6797\t2019-07-31 09:59:00.465319\n",
            "Epoch:  0  [32/43738]\tloss: 0.6724\t2019-07-31 09:59:10.846667\n",
            "Epoch:  0  [33/43738]\tloss: 0.6802\t2019-07-31 09:59:13.703656\n",
            "Epoch:  0  [34/43738]\tloss: nan\t2019-07-31 09:59:16.754535\n",
            "Epoch:  0  [35/43738]\tloss: nan\t2019-07-31 09:59:28.582115\n",
            "Epoch:  0  [36/43738]\tloss: nan\t2019-07-31 09:59:36.514632\n",
            "Epoch:  0  [37/43738]\tloss: nan\t2019-07-31 09:59:41.917623\n",
            "Epoch:  0  [38/43738]\tloss: nan\t2019-07-31 09:59:42.642838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-89b179fcd018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m query_encoder, cand_encoder, rgcn, output_layer = train(\n\u001b[1;32m     26\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     cand_encoder, rgcn, output_layer, save_path, loss_history=loss_history)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-67218cad87a7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, optimizer, loss_fn, src, query_encoder, cand_encoder, rgcn, output_layer, PATH, loss_history, tol)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0;31m# PyG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-57723ecc4a49>\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(instance, query_encoder, cand_encoder)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0msupports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'supports'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupports\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mwhole_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   cands = dict([(v, i) for i, v in \n\u001b[1;32m      7\u001b[0m                 enumerate([cand.lower().strip() \n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mneuralcoref.pyx\u001b[0m in \u001b[0;36mneuralcoref.neuralcoref.NeuralCoref.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mneuralcoref.pyx\u001b[0m in \u001b[0;36mneuralcoref.neuralcoref.NeuralCoref.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/check.py\u001b[0m in \u001b[0;36mchecked_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mExpectedTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Callable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marg_check_adder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/relu.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input__BI)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput__BO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput__BO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__BO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput__BO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/check.py\u001b[0m in \u001b[0;36mchecked_function\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mExpectedTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Callable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marg_check_adder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/affine.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input__BI)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nB\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nI\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput__BI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput__BI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaoOWKGnC2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# g = build_graph(train_src[2], query_encoder, cand_encoder)\n",
        "# g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP2YlyuaKFME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}