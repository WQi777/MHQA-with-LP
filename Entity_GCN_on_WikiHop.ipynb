{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entity-GCN on WikiHop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yg-li/QA-KG-RL/blob/master/Entity_GCN_on_WikiHop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4e6IAlpUi05",
        "colab_type": "text"
      },
      "source": [
        "This notebook is about using Entity-GCN, an algorithm using R-GCN on entity-relations graph to solve the multi-hop QA problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQuAXdFMMZ15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-cluster\n",
        "!pip install torch-geometric\n",
        "# !pip install https://s3.us-east-2.amazonaws.com/dgl.ai/wheels/cuda10.0/dgl-0.3-cp36-cp36m-manylinux1_x86_64.whl\n",
        "  \n",
        "! (if [ \"$(pip freeze | grep spacy | cut -d'=' -f 3)\" != \"2.1.3\" ]; then \\\n",
        "     pip uninstall -y spacy; \\\n",
        "     pip install spacy==2.1.3; \\\n",
        "   fi)\n",
        "!pip install neuralcoref\n",
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZCwquLR9VM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import itertools\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "import neuralcoref\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch import autograd\n",
        "\n",
        "# import dgl\n",
        "# import dgl.function as fn\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import RGCNConv\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvcKylrJU8z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float16\n",
        "\n",
        "elmo = ElmoEmbedder(cuda_device=0 if torch.cuda.is_available() else -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsXK61rj08Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount Google Drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# read in QAngaroo WikiHop\n",
        "wh_data_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/data/qangaroo_v1.1/wikihop'\n",
        "with open(os.path.join(wh_data_path, 'train.json')) as f:\n",
        "  train_src = json.loads(f.read())\n",
        "with open(os.path.join(wh_data_path, 'dev.json')) as f:\n",
        "  dev_src = json.loads(f.read())\n",
        "\n",
        "# # read in HotpotQA\n",
        "# hpqa_data_path = '/gdrive/My Drive/Colab Notebooks/CSML/Project/data/hotpotqa'\n",
        "# with open(os.path.join(hpqa_data_path, 'hotpot_train_v1.1.json')) as f:\n",
        "#   train_src = json.loads(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9qi6k0T9MFM",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xQVn9xr9LMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QueryEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(QueryEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.lstm1 = nn.LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
        "    self.lstm2 = nn.LSTM(512, 128, batch_first=True, bidirectional=True)\n",
        "    self.hidden_map = nn.Linear(256, 128)\n",
        "    self.cell_map = nn.Linear(256, 128)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # batch_size is always 1 as encoding happens per query\n",
        "    x, (h_n, c_n) = self.lstm1(x)\n",
        "    x = self.dropout(F.layer_norm(x, x.shape[1:]))\n",
        "    h_n = self.dropout(F.instance_norm(F.relu(self.hidden_map(h_n))))\n",
        "    c_n = self.dropout(F.instance_norm(F.relu(self.cell_map(c_n))))\n",
        "    x, (q, c_n) = self.lstm2(x, (h_n, c_n))\n",
        "    q = self.dropout(F.layer_norm(q, q.shape[1:]).reshape(1, -1, 256))\n",
        "#     print('query', q, flush=True)\n",
        "    return q\n",
        "  \n",
        "  \n",
        "class CandidateEncoder(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(CandidateEncoder, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(3072, 256)\n",
        "    # the following FF layers applied to concat of query and cand.\n",
        "    self.linear2 = nn.Linear(512, 512)\n",
        "    self.linear3 = nn.Linear(512, 256)\n",
        "    self.bn = nn.BatchNorm1d(1)\n",
        "    \n",
        "  def forward(self, x, q):\n",
        "    x = self.dropout(self.bn(F.relu(self.linear1(x))))\n",
        "    x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(self.bn(F.relu(self.linear2(x))))\n",
        "    x = self.dropout(self.bn(F.relu(self.linear3(x))))\n",
        "#     print('cand', x, flush=True)\n",
        "    return x\n",
        "  \n",
        "  \n",
        "class PyG_RGCN(nn.Module):\n",
        "  def __init__(self, dropout=0, L=3):\n",
        "    super(PyG_RGCN, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.L = L\n",
        "    # all R-GCN layers are sharing weights\n",
        "    self.conv = RGCNConv(256, 256, num_relations=4, num_bases=4)\n",
        "    self.gating = nn.Linear(512, 1)\n",
        "    \n",
        "  def forward(self, x, edge_index, edge_type):\n",
        "    # L is the number of R-GCN layers\n",
        "    for _ in range(self.L):\n",
        "      u = F.instance_norm(self.conv(x, edge_index, edge_type))\n",
        "      a = torch.sigmoid(self.gating(torch.cat((u, x), dim=-1)))\n",
        "      x = self.dropout(torch.tanh(u) * a + x * (1-a))\n",
        "#     print('x', x, flush=True)\n",
        "    return x \n",
        "\n",
        "  \n",
        "# class RGCNLayer(nn.Module): # RGCN layer implemented with DGL\n",
        "#   def __init__(self, in_feat, out_feat, num_rels, num_bases=-1, bias=True,\n",
        "#                activation=None):#, is_input_layer=False):\n",
        "#     super(RGCNLayer, self).__init__()\n",
        "#     self.in_feat = in_feat\n",
        "#     self.out_feat = out_feat\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.bias = bias\n",
        "#     self.activation = activation\n",
        "\n",
        "#     # sanity check\n",
        "#     if self.num_bases <= 0 or self.num_bases > self.num_rels:\n",
        "#       self.num_bases = self.num_rels\n",
        "\n",
        "#     # weight bases in equation (3)\n",
        "#     self.weight = nn.Parameter(torch.Tensor(self.num_rels, self.in_feat,\n",
        "#                                             self.out_feat))\n",
        "\n",
        "#     # add bias\n",
        "#     if self.bias:\n",
        "#       self.bias = nn.Parameter(torch.Tensor(out_feat))\n",
        "\n",
        "#     # init trainable parameters\n",
        "#     nn.init.xavier_uniform_(self.weight,\n",
        "#                             gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     weight = self.weight\n",
        "\n",
        "#     def message_func(edges):\n",
        "#       w = weight[edges.data['rel_type']]\n",
        "#       msg = torch.bmm(edges.src['x'].unsqueeze(1), w).squeeze()\n",
        "#       return {'msg': msg}\n",
        "\n",
        "#     def apply_func(nodes):\n",
        "#       h = nodes.data['h']\n",
        "#       if self.bias is not None:\n",
        "#         h = h + self.bias\n",
        "#       if self.activation:\n",
        "#         h = self.activation(h)\n",
        "#       return {'h': h}\n",
        "\n",
        "#     g.update_all(message_func, fn.sum(msg='msg', out='h'), apply_func)\n",
        "    \n",
        "\n",
        "# class DGL_RGCN(nn.Module):\n",
        "#   def __init__(self, num_rels=4, num_bases=-1, num_layers=3, dropout=0):\n",
        "#     super(DGL_RGCN, self).__init__()\n",
        "#     self.num_rels = num_rels\n",
        "#     self.num_bases = num_bases\n",
        "#     self.num_layers = num_layers\n",
        "#     self.dropout = nn.Dropout(p=dropout)\n",
        "#     self.conv = RGCNLayer(256, 256, self.num_rels, self.num_bases)\n",
        "#     self.gating = nn.Linear(512, 1)\n",
        "\n",
        "#   def forward(self, g):\n",
        "#     for _ in range(self.num_layers):\n",
        "#       self.conv(g)\n",
        "#       u = g.ndata.pop('h')\n",
        "#       a = torch.sigmoid(self.gating(torch.cat((u, g.ndata['x']), dim=-1)))\n",
        "#       g.ndata['x'] = self.dropout(torch.tanh(u) * a + g.ndata['x'] * (1-a))\n",
        "#     return g.ndata.pop('x')\n",
        "  \n",
        "\n",
        "class OutputLayer(nn.Module):\n",
        "  def __init__(self, dropout=0):\n",
        "    super(OutputLayer, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.linear1 = nn.Linear(512, 256)\n",
        "    self.linear2 = nn.Linear(256, 128)\n",
        "    self.linear3 = nn.Linear(128, 1)\n",
        "    self.bn256 = nn.BatchNorm1d(256)\n",
        "    self.bn128 = nn.BatchNorm1d(128)\n",
        "    \n",
        "  def forward(self, x, q, node_mask):\n",
        "    # batch_size is 1 as instances have different number of candidates\n",
        "    if not x.shape[0] == q.shape[0]:\n",
        "      x = torch.cat((q.expand(x.shape[0], -1), x), dim=-1)\n",
        "    else:\n",
        "      x = torch.cat((q, x), dim=-1)\n",
        "    x = self.dropout(self.bn256(F.relu(self.linear1(x))))\n",
        "    x = self.dropout(self.bn128(F.relu(self.linear2(x))))\n",
        "    x = self.linear3(x)\n",
        "    x *= node_mask\n",
        "#     print('out', x, flush=True)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "labw0S-477BQ",
        "colab_type": "text"
      },
      "source": [
        "# Build Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd3LnbHdAx4x",
        "colab_type": "text"
      },
      "source": [
        "## Extract nodes and edges & Encode mentions with ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UewhVYZsqXsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_info(query, docs, whole_doc, cands, answer,\n",
        "                 query_encoder, cand_encoder):\n",
        "  ''' extract the information needed to build Entity-GCN's graph\n",
        "  Args:\n",
        "    query: the query\n",
        "    docs: spacy annotated documents\n",
        "    whole_doc: spacy annotated concatenated documents\n",
        "    cands: candidates\n",
        "    answer: the correct answer\n",
        "    query_encoder: the encoder for query\n",
        "    cand_encoder: the encoder for candidates given query embedding\n",
        "  Returns:\n",
        "    nodes: nodes of the graph \\\\ dict{id : candidate id (-1 if query entity)}\n",
        "    node_types: 1 for answer, 0 for other candidates, -1 for query entity\n",
        "    node_embeddings: the contextualized embedding of mentions of candidates\n",
        "    query_embedding: the emebdding of query\n",
        "    doc_based_edges: edges that connect mentions in the same document \n",
        "    match_edges: edges that connect exact match \\\\ set((node1, node2))\n",
        "    coref_edges: edges that connect mentions in the same coreference chain \n",
        "    compl_edges: edges that connect all nodes that have not been connected by \n",
        "                 any other types of edges \\\\ set((node1, node2))\n",
        "  ''' \n",
        "  # extract the query entity\n",
        "  query_entity = ' '.join(query.split(' ')[1:])\n",
        "  cands[query_entity] = -1\n",
        "  \n",
        "  # matcher for candidates and query entity\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  patterns = [nlp.make_doc(cand) for cand in cands]\n",
        "  matcher.add(\"CandList\", None, *patterns)\n",
        "\n",
        "  # get embedding of query, q\n",
        "  query_embedding = query_encoder(\n",
        "      torch.as_tensor(\n",
        "          elmo.embed_sentence(\n",
        "              query.split(' ')[0].split('_') + \n",
        "              query.split(' ')[1:]).reshape(1, -1, 3072), \n",
        "          device=device, dtype=dtype))\n",
        "  # get elmo for all documents\n",
        "  docs_elmo = [torch.as_tensor(d.reshape(1, -1, 3072), device=device, dtype=dtype)\n",
        "               for d in elmo.embed_sentences(\n",
        "                   [[w.text for w in doc] for doc in docs])]\n",
        "  \n",
        "  nodes = {}\n",
        "  node_types = []\n",
        "  node_embeddings = []\n",
        "  with_edges = set()\n",
        "  \n",
        "  # sets to store edges\n",
        "  doc_based_edges = set()\n",
        "  match_edges = set()\n",
        "  coref_edges = set()\n",
        "  compl_edges = set()\n",
        "  \n",
        "  # auxiliary variables for cross-document coreference\n",
        "  out_coref_clusters = [[m.text for m in c.mentions] \n",
        "                        for c in whole_doc._.coref_clusters]\n",
        "  out_coref_tmps = [set()] * len(out_coref_clusters) # nodes in same coref chain\n",
        "  \n",
        "  # accumulate nodes, add the doc_based & coreference edges\n",
        "  for doc_id, doc in enumerate(docs):\n",
        "    matches = matcher(doc)\n",
        "    # text = ' '.join([toc.text for toc in doc])\n",
        "    in_coref_clusters = [[m.text for m in c.mentions] \n",
        "                         for c in doc._.coref_clusters]\n",
        "    in_coref_tmps = [set()] * len(in_coref_clusters) # nodes in same coref chain\n",
        "    doc_tmp = set() # nodes in the same doc\n",
        "    for _, start, end in matches:\n",
        "      match = doc[start:end].text\n",
        "      new_node = len(nodes)\n",
        "      doc_tmp.add(new_node)\n",
        "      nodes[new_node] = cands.get(match, -1)\n",
        "      node_types.append([1 if match == answer \n",
        "                         else -1 if match == query_entity \n",
        "                         else 0])\n",
        "      match_elmo = docs_elmo[doc_id][:, start:end, :].mean(dim=1, keepdim=True)\n",
        "      node_embeddings.append(cand_encoder(match_elmo, query_embedding))\n",
        "      for i, cluster in enumerate(in_coref_clusters):\n",
        "        if match in cluster:\n",
        "          in_coref_tmps[i].add(new_node)\n",
        "      for i, cluster in enumerate(out_coref_clusters):\n",
        "        if match in cluster:\n",
        "          out_coref_tmps[i].add(new_node)\n",
        "          \n",
        "    for pair in itertools.combinations(doc_tmp, 2):\n",
        "      doc_based_edges.add(pair) # doc_based edges\n",
        "      with_edges.update(pair)\n",
        "    for coref_tmp in in_coref_tmps:\n",
        "      for pair in itertools.combinations(coref_tmp, 2):\n",
        "        coref_edges.add(pair) # within-document coref_edges\n",
        "        with_edges.update(pair)\n",
        "        \n",
        "  # cross-document coref_edges\n",
        "  for coref_tmp in out_coref_tmps:\n",
        "    for pair in itertools.combinations(coref_tmp, 2):\n",
        "      coref_edges.add(pair) # cross-document coref_edges\n",
        "      with_edges.update(pair)\n",
        "      \n",
        "  # add exact match edges\n",
        "  for i, j in itertools.combinations(nodes, 2):\n",
        "    if nodes[i] == nodes[j]:\n",
        "      match_edges.add((i,j))\n",
        "      with_edges.update((i,j))\n",
        "      \n",
        "  # add complement edges\n",
        "  isolated_nodes = set(nodes) - with_edges\n",
        "  if isolated_nodes:\n",
        "    for pair in itertools.combinations(isolated_nodes, 2):\n",
        "      compl_edges.add(pair)\n",
        "      \n",
        "  return nodes, node_types, node_embeddings, query_embedding, \\\n",
        "         [doc_based_edges, match_edges, coref_edges, compl_edges]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE_E01PXA6ne",
        "colab_type": "text"
      },
      "source": [
        "## PyG graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na1M8d7XqM2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_pyg_graph(nodes, node_types, node_embeddings, query_embedding, edges):\n",
        "  # nodes\n",
        "  x = torch.cat(node_embeddings).squeeze()\n",
        "  node_name = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  node_mask = (tmp >= 0).to(device, dtype) # whether the node is in candidate list\n",
        "  y = (tmp > 0).to(device, dtype) # target \n",
        "\n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "\n",
        "  data = Data(x=x, node_name=node_name, node_mask=node_mask, \n",
        "              query=query_embedding.reshape(-1, 256), y=y,\n",
        "              edge_index=edge_index.t().contiguous(), edge_type=edge_type)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SijcVUbVDFQ",
        "colab_type": "text"
      },
      "source": [
        "## DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE-MkrfBVNou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dgl_graph(nodes, node_types, \n",
        "                    node_embeddings, query_embedding, edges):\n",
        "  g = dgl.DGLGraph()\n",
        "  \n",
        "  # nodes\n",
        "  g.add_nodes(len(nodes))\n",
        "  g.ndata['x'] = torch.cat(node_embeddings).squeeze()\n",
        "  g.ndata['name'] = torch.tensor(list(nodes.values()), device=device, dtype=dtype)\n",
        "  tmp = torch.tensor(node_types)\n",
        "  g.ndata['mask'] = (tmp >= 0).to(device, dtype)\n",
        "  g.ndata['y'] = (tmp > 0).to(device, dtype)\n",
        "  g.ndata['q'] = query_embedding.reshape(-1, 256).expand(g.number_of_nodes(), -1)\n",
        "  \n",
        "  # edges\n",
        "  edge_index = torch.zeros(0, 2).to(device, torch.long)\n",
        "  edge_type = torch.zeros(0).to(device, torch.long)\n",
        "  for i, e in enumerate(edges):\n",
        "    if len(e) > 0:\n",
        "      tmp = torch.tensor(list(e), dtype=dtype, device=device)\n",
        "      # add edges with swapped direction to make the graph undirected\n",
        "      tmp = torch.cat((tmp, \n",
        "                       torch.index_select(tmp, 1, torch.tensor([1,0], device=device))), \n",
        "                      0)\n",
        "      edge_index = torch.cat((edge_index, tmp.to(torch.long)), 0)\n",
        "      edge_type = torch.cat((edge_type, torch.ones(tmp.shape[0]).to(device, torch.long) * i), 0)\n",
        "  g.add_edges(edge_index[:,0], edge_index[:,1])    \n",
        "  g.edata['rel_type'] = edge_type\n",
        "  \n",
        "  return g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoOp15T9Sxb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_graph(instance, query_encoder, cand_encoder, extract=False):\n",
        "  query = instance.get('query').strip()\n",
        "  supports = [text.lower() for text in instance.get('supports')]\n",
        "  docs = [nlp(text) for text in supports]\n",
        "  whole_doc = nlp(' '.join(supports))\n",
        "  cands = dict([(v, i) for i, v in \n",
        "                enumerate([cand.lower().strip() \n",
        "                           for cand in instance.get('candidates')])])\n",
        "  answer = instance.get('answer')\n",
        "  \n",
        "  # extract nodes, edges, and embeddings\n",
        "  nodes, node_types, node_embeddings, query_embedding, edges = \\\n",
        "    extract_info(query, docs, whole_doc, cands, answer, \n",
        "                 query_encoder, cand_encoder)\n",
        "  if extract:\n",
        "    return nodes, node_types, node_embeddings, query_embedding, edges\n",
        "  \n",
        "  # build PyG graph\n",
        "  g = build_pyg_graph(nodes, node_types, \n",
        "                      node_embeddings, query_embedding, edges)\n",
        "\n",
        "  # build DGL graph\n",
        "#   g = build_dgl_graph(nodes, node_types, \n",
        "#                       node_embeddings, query_embedding, edges)\n",
        "  return g # query, cands, answer   TODO: check the output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdURez7sCuPz",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSnfyPOZgIlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch, step, loss_history, optimizer,\n",
        "                query_encoder, cand_encoder, rgcn, output_layer, PATH):\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'step': step,\n",
        "        'loss_history': loss_history,\n",
        "        'query_encoder': query_encoder.state_dict(),\n",
        "        'cand_encoder': cand_encoder.state_dict(),\n",
        "        'rgcn': rgcn.state_dict(),\n",
        "        'output_layer': output_layer.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "  }, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x489ulHRV71k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs, step, batch_size, optimizer, loss_fn, src, query_encoder, \n",
        "          cand_encoder, rgcn, output_layer, PATH, loss_history=[], tol=1e-3):\n",
        "  query_encoder.train()\n",
        "  cand_encoder.train()\n",
        "  rgcn.train()\n",
        "  output_layer.train()\n",
        "  for e in epochs:\n",
        "    random.shuffle(src)\n",
        "    for i in range(step, len(src)):\n",
        "#       if i % batch_size == 0:\n",
        "        # start of a batch\n",
        "      optimizer.zero_grad()\n",
        "      try:\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "        # TODO: link predition\n",
        "        # PyG\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query, g.node_mask)\n",
        "        loss = loss_fn(pred, g.y) # TODO: maybe need to scale for batch\n",
        "\n",
        "#         # DGL\n",
        "#         out = rgcn(g)\n",
        "#         pred = output_layer(out, g.ndata['q'], g.ndata['mask'])\n",
        "#         loss = loss_fn(pred, g.ndata['y'])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      except:\n",
        "        print('Fail graph with id: {}'.format(src[i].get('id')), flush=True)\n",
        "        continue\n",
        "      print('Epoch: {:2d}  [{:d}/{:d}]\\tloss: {:.4f}\\t{}'.format(\n",
        "          e, i+1, len(src), loss.item(), datetime.now()), flush=True)\n",
        "      loss_history.append(loss.item())\n",
        "    \n",
        "      if i != 0 and i % batch_size == 0 or i == len(src)-1:\n",
        "        # end of a batch\n",
        "        save_models(e, i+1, loss_history, optimizer, \n",
        "            query_encoder, cand_encoder, rgcn, output_layer, \n",
        "            PATH)\n",
        "        print('Model saved', flush=True)\n",
        "        \n",
        "    # end of epoch\n",
        "    save_models(e+1, 0, loss_history, optimizer, \n",
        "        query_encoder, cand_encoder, rgcn, output_layer, \n",
        "        PATH)\n",
        "    if loss_history[-10] - loss_history[-1] < tol:\n",
        "      return query_encoder, cand_encoder, rgcn, output_layer\n",
        "  return query_encoder, cand_encoder, rgcn, output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frpCGWaFWuLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loss_fn, src, query_encoder, cand_encoder, rgcn, output_layer):\n",
        "  query_encoder.eval()\n",
        "  cand_encoder.eval()\n",
        "  rgcn.eval()\n",
        "  output_layer.eval()\n",
        "  \n",
        "  num_processed_graphs = 0\n",
        "  loss_history = []\n",
        "  acc = 0.\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(src)):\n",
        "      try:\n",
        "        g = build_graph(src[i], query_encoder, cand_encoder)\n",
        "        # PyG\n",
        "        out = rgcn(g.x, g.edge_index, g.edge_type)\n",
        "        pred = output_layer(out, g.query, g.node_mask)\n",
        "        \n",
        "        loss_history.append(loss_fn(pred, g.y).item())\n",
        "        acc += (g.y[pred.argmax(), 0] == 1).item()\n",
        "        num_processed_graphs += 1\n",
        "      except:\n",
        "        print('Fail graph with id: {}'.format(src[i].get('id')), flush=True)\n",
        "        continue\n",
        "      if i % 32 == 0:\n",
        "        print('[{:d}/{:d}]\\tloss: {:.4f}\\tacc: {:.1f}\\t{}'.format(\n",
        "            num_processed_graphs, len(src), loss_history[-1], acc, datetime.now()), flush=True)\n",
        "        \n",
        "  return acc/num_processed_graphs, loss_history     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pp7lxklJwdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # parameters\n",
        "# epochs = range(20)\n",
        "# step = 0\n",
        "# batch_size = 32\n",
        "# L = 3 # number of R-GCN layers\n",
        "# lr = 1e-4\n",
        "# dropout = 0\n",
        "# save_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/checkpoint/entity_gcn_gpu.tar'\n",
        "\n",
        "# # models\n",
        "# query_encoder = QueryEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "# cand_encoder = CandidateEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "# # rgcn = DGL_RGCN(dropout=dropout, num_layers=L).to(device, dtype=dtype)\n",
        "# rgcn = PyG_RGCN(dropout=dropout, L=L).to(device, dtype=dtype)\n",
        "# output_layer = OutputLayer(dropout=dropout).to(device, dtype=dtype)\n",
        "\n",
        "# optimizer = Adam(\n",
        "#     itertools.chain(\n",
        "#         query_encoder.parameters(), \n",
        "#         cand_encoder.parameters(), \n",
        "#         rgcn.parameters(), \n",
        "#         output_layer.parameters()), \n",
        "#     lr=lr,\n",
        "#     eps=1e-4)\n",
        "# loss_fn = nn.BCEWithLogitsLoss()\n",
        "# loss_history = []\n",
        "\n",
        "# # load checkpoint\n",
        "# if os.path.isfile(save_path):\n",
        "#   checkpoint = torch.load(save_path)\n",
        "#   epochs = range(checkpoint['epoch'], 20)\n",
        "#   step = checkpoint['step']\n",
        "#   loss_history = checkpoint['loss_history']\n",
        "#   query_encoder.load_state_dict(checkpoint['query_encoder'])\n",
        "#   cand_encoder.load_state_dict(checkpoint['cand_encoder'])\n",
        "#   rgcn.load_state_dict(checkpoint['rgcn'])\n",
        "#   output_layer.load_state_dict(checkpoint['output_layer'])\n",
        "#   optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "# query_encoder, cand_encoder, rgcn, output_layer = train(\n",
        "#     epochs, step, batch_size, optimizer, loss_fn, train_src, query_encoder, \n",
        "#     cand_encoder, rgcn, output_layer, save_path, loss_history=loss_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXaoOWKGnC2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# g = build_graph(train_src[2], query_encoder, cand_encoder)\n",
        "# nodes, node_types, node_embeddings, query_embedding, edges = build_graph(train_src[76], query_encoder, cand_encoder, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2ooSEKN63DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = 3 # number of R-GCN layers\n",
        "dropout = 0\n",
        "save_path='/gdrive/My Drive/Colab Notebooks/CSML/Project/checkpoint/entity_gcn_gpu.tar'\n",
        "\n",
        "query_encoder = QueryEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "cand_encoder = CandidateEncoder(dropout=dropout).to(device, dtype=dtype)\n",
        "# rgcn = DGL_RGCN(dropout=dropout, num_layers=L).to(device, dtype=dtype)\n",
        "rgcn = PyG_RGCN(dropout=dropout, L=L).to(device, dtype=dtype)\n",
        "output_layer = OutputLayer(dropout=dropout).to(device, dtype=dtype)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "checkpoint = torch.load(save_path)\n",
        "query_encoder.load_state_dict(checkpoint['query_encoder'])\n",
        "cand_encoder.load_state_dict(checkpoint['cand_encoder'])\n",
        "rgcn.load_state_dict(checkpoint['rgcn'])\n",
        "output_layer.load_state_dict(checkpoint['output_layer'])\n",
        "\n",
        "acc, loss_history = test(loss_fn, dev_src, \n",
        "                         query_encoder, cand_encoder, rgcn, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Q2hvQCKUPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}